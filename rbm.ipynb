{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacoDLC/deeplearning-az/blob/master/rbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FouiEJyx1zfZ"
      },
      "source": [
        "# Máquinas de Boltzmann\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clonar repositorio de GitHub para acceder a los datasets"
      ],
      "metadata": {
        "id": "_0We3XRSCfLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PacoDLC/deeplearning-az"
      ],
      "metadata": {
        "id": "Xiw8iJ9QClDz",
        "outputId": "923dea76-16c3-4e45-b969-095083726c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning-az'...\n",
            "remote: Enumerating objects: 10303, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 10303 (delta 59), reused 48 (delta 38), pack-reused 10201 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10303/10303), 297.64 MiB | 29.47 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "Updating files: 100% (20244/20244), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Montar conexión a Google Drive"
      ],
      "metadata": {
        "id": "pbeBbz_VC-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yFgDekzTDB-z",
        "outputId": "76a0ebe1-d78a-494e-ce46-25af041a1141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importación de las librerías"
      ],
      "metadata": {
        "id": "T25kXVPSCdlc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmeIv8QGECQg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Librerías de PyTorch\n",
        "import torch\n",
        "import torch.nn as nn # Neural Network\n",
        "import torch.nn.parallel # Cálculos en paralelo (optimización)\n",
        "import torch.optim as optim # Optimizador para minimizar el error\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtPJAjYkEGaI"
      },
      "source": [
        "#Importación del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg2J9cekEQMB"
      },
      "source": [
        "movies = pd.read_csv(\"/content/deeplearning-az/updated/Part 5 - Boltzmann Machines (BM)/ml-1m/movies.dat\",\n",
        "                     sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users  = pd.read_csv(\"/content/deeplearning-az/updated/Part 5 - Boltzmann Machines (BM)/ml-1m/users.dat\",\n",
        "                     sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings  = pd.read_csv(\"/content/deeplearning-az/updated/Part 5 - Boltzmann Machines (BM)/ml-1m/ratings.dat\",\n",
        "                       sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH51w40MERH4"
      },
      "source": [
        "# Preparación del conjunto de entrenamiento y el conjunto de pruebas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bACx4jriEZ3x"
      },
      "source": [
        "training_set = pd.read_csv(\"/content/deeplearning-az/updated/Part 5 - Boltzmann Machines (BM)/ml-100k/u1.base\",\n",
        "                           sep = \"\\t\", header = None)\n",
        "training_set = np.array(training_set, dtype = \"int\")\n",
        "test_set = pd.read_csv(\"/content/deeplearning-az/updated/Part 5 - Boltzmann Machines (BM)/ml-100k/u1.test\",\n",
        "                       sep = \"\\t\", header = None)\n",
        "test_set = np.array(test_set, dtype = \"int\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofQkyqyFPqh"
      },
      "source": [
        "# Obtención del número de usuarios y películas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN5uvKN6FaL9",
        "outputId": "19439912-7e13-4002-9345-87887d34ad0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        "print(nb_users)\n",
        "print(nb_movies)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943\n",
            "1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGgaZpn5Fa6G"
      },
      "source": [
        "\n",
        "# Conversión de los datos en una matriz con los usuarios en líneas y las películas en columnas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWNIC6lWFoXW"
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwRMMksoFqQ0"
      },
      "source": [
        "# Conversión de los datos en Torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SM3uCZ-HlqW"
      },
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heRglqRFHtWu"
      },
      "source": [
        "# Convertir las clasificaciones en clasificaciones binarias 1 (Le gusta) o 0 (No le gusta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT-MZEY2HuSu"
      },
      "source": [
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jhdf4bEHwGv"
      },
      "source": [
        "# Creación de la arquitectura de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEWTCTJOH2b_"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, nv, nh):\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        self.a = torch.randn(1, nh)\n",
        "        self.b = torch.randn(1, nv)\n",
        "    def sample_h(self, x):\n",
        "        wx = torch.mm(x, self.W.t())\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        p_h_given_v = torch.sigmoid(activation)\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "    def sample_v(self, y):\n",
        "        wy = torch.mm(y, self.W)\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        p_v_given_h = torch.sigmoid(activation)\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7P8ueOuH5SW"
      },
      "source": [
        "# Entrenamiento de la RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olTCFYxfH9sv"
      },
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user:id_user+batch_size]\n",
        "        v0 = training_set[id_user:id_user+batch_size]\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
        "        s += 1.\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP1gfcsGH_wn"
      },
      "source": [
        "# Testing de la RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97W2DLYQIGey"
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}